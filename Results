Solution for SVM Programming Task

Part 1:
Solving Assignment 71 using svm
 (1)
 Since the Data given is linearly separable in 2 dimensions it can be solved using linear kernal.
 I have plotted the decision boundary and the margin using linear kernel and can be checked via the resulting figure as well.
 
Performance of Linear and Rbf kernal was best for this task.

2)
Support vectors for Assignment 71 with Parameter C=0.05
[[ 1.  3.]
 [ 1.  2.]
 [ 2.  2.]
 [ 2.  4.]
 [ 1. -2.]
 [ 3.  1.]
 [ 3.  0.]
 [ 5.  1.]]
Support vectors for Assignment 71 with Parameter C=0.1
[[ 1.  3.]
 [ 1.  2.]
 [ 2.  2.]
 [ 1. -2.]
 [ 3.  1.]
 [ 3.  0.]]
Support vectors for Assignment 71 with Parameter C=1
[[ 2.  2.]
 [ 3.  1.]]
Support vectors for Assignment 71 with Parameter C=3
[[ 2.  2.]
 [ 3.  1.]]

3)

For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. 
Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points

4)
Effecient range of C for this task was 0.05 - < 0.5 (less than 0.5)

Check plot and output_file for results.

#####################################################################################

Part two:

1)
FOr tranining PA-H_t2.dat Linear kernel is the most appropriate classifier
For all others PA-H_t3 - PA-H_t7 Rbf kernel is the most appropriate classifier as the contained data is not linearly separable in 2 dimensions

2) You can check the (Created)Output_file  for support vectors of different svms using different C parameters.

3) The effect of C paramenter is same as mentioned above.
4) Effecient range of C is between 0.1 to 100 for almost all the cases.
